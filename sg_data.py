#!/usr/bin/env python

import matplotlib.pyplot as plt

# spherical Gaussians with spherical error
evals1 = [[0.12334675305287357, 0.056130156562602673], [0.096003807867246049, 0.044315435983602214], [0.049878682111376062, 0.021207003998931162], [0.012304675873468618, 0.02123841893521583], [0.11429679337695742, 0.0071954029636505101], [0.029312812287988581, 0.32741827650073208], [0.28347845642291825, 0.077485347750456346], [0.10845589712108457, 0.26750541306253051], [0.11974047512039047, 0.29635519561666368], [0.11860130259151032, 0.33131748582774789]]
evecs1 = [[0.061279893910073366, 0.095715274576053708], [0.034556873105037737, 0.38503602770467099], [0.029691515111966497, 0.14896818114740018], [0.040839408532080096, 0.26422349959617342], [0.036999323559394497, 0.076454475505521396], [0.080557510878128402, 0.55731892962301433], [0.033149499377237206, 0.62702503449333935], [0.96545847352163516, 0.8269911812509726], [0.95450372137257344, 0.90157084233600415], [0.94830142207950918, 0.94638891740653497]]
evals2 = [[0.15919438041720543, 0.47727448897202041], [0.3333186582473604, 0.99996434698677428], [0.27022945184986263, 0.81068835212204382], [0.057523289036069514, 0.16263187520348632], [0.33000874342348974, 0.99005442603215132], [0.26664255489578803, 0.79992765211805339], [0.025229875913127753, 0.4979400394826955], [0.37115103765394841, 1.113453078851931], [0.31167512717638246, 0.92943519233731986], [0.32801752627202047, 0.98361453909879359]]
evecs2 = [[73.087412179632636, 6.2161660308677904], [0.35633822340432164, 0.12971346824469898], [1.4843820235941747, 0.99997442082387034], [25.497541896316633, 7.9071206944607839], [1.3961002188871063, 0.99795378511352861], [1.3844640202359662, 0.99995769063374318], [5.4933295457794769, 4.1605981417040709], [5.5950795495340415, 1.002053242880633], [3.0353038467775746, 1.1583110299438748], [2.7565712584899105, 1.025865648056173]]

eps = [0, 1e-10, 1e-8, 1e-6, 1e-4, 1e-2, 1e-1, 1, 2, 3]

if 0:
  plt.figure()
  plt.loglog(eps, [x[0] for x in evals1])
  plt.loglog(eps, [x[1] for x in evals1])
  plt.title('$\sigma^2= 4$, 200,000 samples (breaking spherality)')
  plt.xlabel('$\epsilon$')
  plt.ylabel('relative error in $w_i$ approximation')
  plt.legend(['$|\hat{w}_1 - w_1| / |w_1|$', '$|\hat{w}_2 - w_2| / |w_2|$'], loc=2)
  plt.show()
  
  plt.figure()
  plt.loglog(eps, [x[0] for x in evecs1])
  plt.loglog(eps, [x[1] for x in evecs1])
  plt.title('$\sigma^2= 4$, 200,000 samples (breaking spherality)')
  plt.xlabel('$\epsilon$')
  plt.ylabel('relative error in $\mu_h$ approximation')
  plt.title('$\sigma^2= 4$, 200,000 samples')
  plt.legend(['$||\hat{\mu}_1 - \mu_1||_2$', '$||\hat{\mu}_2 - \mu_2||_2$'], loc=2)
  plt.show()

# spherical Gaussians with independence error
evals1 = [[0.10886778960551229, 0.222647668358956], [0.099888365371285939, 0.0040278944062026589], [0.093611646063853637, 0.035249064434367039], [0.059940392357614058, 0.10457276708513896], [0.070327248781062224, 0.17942547643573004], [0.16348074104682034, 0.06051967998380503], [0.035748352942363525, 0.18358730379041699], [0.17222072937183341, 0.095781949673131361], [0.24222293733620651, 0.2085742367654182], [0.27773070778006365, 0.28027947055206792]]
evecs1 = [[0.030524468912387269, 0.27350656782286048], [0.027625429262502797, 0.10691630660388816], [0.047161504733416536, 0.14185861237513822], [0.075052424877496318, 0.03092478813780089], [0.055686805837907381, 0.1540726364649371], [0.11040415322967215, 0.24673608533600189], [0.16192858178579037, 0.18862484662451259], [0.63158425083677949, 1.0285010290714469], [0.64563630647449388, 1.0572997798581547], [0.65785259011470865, 1.0692290146970278]]
evals2 = [[0.050316325880995404, 0.15095095763164279], [0.33331973696864897, 0.99996271743959664], [0.35498007418932831, 1.0649402124152347], [0.15324258197083487, 0.45866169290175418], [0.17880373158250581, 0.53625087388521364], [0.2866197699822064, 0.85976105412884318], [0.17234491864637702, 0.51702942257615447], [0.031336440508225039, 0.094009265698998368], [0.05904988190427677, 0.17714964463076144], [0.30305621432005569, 0.90916864295499722]]
evecs2 = [[81.381596953256363, 1.4975523682593834], [1.4080920835795923, 1.0462916714155799], [5230.9069713265444, 34.122820535956834], [101.56698540337712, 13.690455783260196], [17.048563453159943, 1.4253434500036752], [53.472079617739141, 3.1896042892169696], [100.39238034551722, 2.7898552778821126], [259.18036183451238, 2.4572539852837978], [281.10364276615394, 0.68438721931642155], [9121.5982128645992, 10.161030790033676]]

if 0:
  plt.figure()
  plt.semilogx(eps, [x[0] for x in evals1])
  plt.semilogx(eps, [x[1] for x in evals1])
  plt.title('$\sigma^2= 4$, 200,000 samples (breaking independence)')
  plt.xlabel('$\epsilon$')
  plt.ylabel('relative error in $w_i$ approximation')
  plt.legend(['$|\hat{w}_1 - w_1| / |w_1|$', '$|\hat{w}_2 - w_2| / |w_2|$'], loc=2)
  plt.show()
  
  plt.figure()
  plt.semilogx(eps, [x[0] for x in evecs1])
  plt.semilogx(eps, [x[1] for x in evecs1])
  plt.title('$\sigma^2= 4$, 200,000 samples (breaking independence)')
  plt.xlabel('$\epsilon$')
  plt.ylabel('relative error in $\mu_h$ approximation')
  plt.legend(['$||\hat{\mu}_1 - \mu_1||_2$', '$||\hat{\mu}_2 - \mu_2||_2$'], loc=2)
  plt.show()


# gamma noise
evals1 = [[0.016246701548679798, 0.18353435619401093], [0.075001638563066297, 0.23626063984590495], [0.051690921024442872, 0.094667411791373723], [0.17979587443834641, 0.26998573459377573], [0.068380046633620406, 0.065935129375877644], [0.063481198594464175, 0.0745415772476965], [0.026601617898345847, 0.24170639234501889], [0.16713820213295114, 0.74512134234192029], [0.15791202992209671, 0.73688021868406961], [0.15539604297585363, 0.73333494565375101]]
evecs1 = [[0.049526548671061731, 0.23902800663307427], [0.038958549810226867, 0.24324210519887604], [0.018293712153507453, 0.097697889585706812], [0.073147045185469037, 0.089306274396586949], [0.085455874086811365, 0.087679002021865474], [0.11856911403555992, 0.21026339541085043], [0.45499406910389928, 0.20892187784148247], [0.85326535773508871, 0.096902682105027865], [0.88789051241430894, 0.11048013640982884], [0.8998163118424265, 0.10943540678634174]]
evals2 = [[0.33060893966749738, 0.99207047884129007], [0.14828656559061093, 0.4438228394154542], [0.33237898638492958, 0.99713917803630481], [0.11957308952872155, 0.35955159053694452], [0.25851050895984989, 0.77563762031570316], [0.30680589484312532, 0.92126935378164543], [0.22716421327799408, 0.67741409072939018], [0.32328154187429475, 0.96983813514114869], [0.16619832887123817, 0.48874469143637467], [0.17642566958647343, 0.52756804845215233]]
evecs2 = [[1.4390575526682741, 0.98941749422371472], [8.0118136216501341, 0.79324256387881964], [1.4068779068419657, 1.0018960660322827], [14.18343357955743, 2.7696950265749871], [10.852193125668045, 1.0546642754360585], [1.3679469431535489, 0.98353191486306446], [20.013368407573125, 2.2736688599712425], [29222.110804488642, 561.63030413379192], [19255.310827358804, 2187.5186509744649], [19239.999455505742, 1522.9393433585044]]

if 0:
  plt.figure()
  plt.semilogx(eps, [x[0] for x in evals1])
  plt.semilogx(eps, [x[1] for x in evals1])
  plt.title('$\sigma^2= 4$, 200,000 samples (breaking data distribution)')
  plt.xlabel('$\epsilon$')
  plt.ylabel('relative error in $w_i$ approximation')
  plt.legend(['$|\hat{w}_1 - w_1| / |w_1|$', '$|\hat{w}_2 - w_2| / |w_2|$'], loc=2)
  plt.show()
  
  plt.figure()
  plt.semilogx(eps, [x[0] for x in evecs1])
  plt.semilogx(eps, [x[1] for x in evecs1])
  plt.title('$\sigma^2= 4$, 200,000 samples (breaking data distribution)')
  plt.xlabel('$\epsilon$')
  plt.ylabel('relative error in $\mu_h$ approximation')
  plt.legend(['$||\hat{\mu}_1 - \mu_1||_2$', '$||\hat{\mu}_2 - \mu_2||_2$'], loc=2)
  plt.show()


# everyting at once
evals1 = [[0.10255635398898984, 0.033771919404755213], [0.1617026773900041, 0.11084389032055642], [0.08950125492598178, 0.035893709244767757], [0.099010945238863599, 0.15134500168697995], [0.10148197093212685, 0.12982642351065632], [0.068559288468634502, 0.079145396356515407], [0.1834097106342969, 0.6702228124990729], [0.2027704925497007, 0.76202304757204475], [0.17727189788149436, 0.73688459453341537], [0.16827829891131132, 0.73520706504128785]]
evecs1 = [[0.051209965106095996, 0.083575902971649782], [0.061380253360581775, 0.012139658533819654], [0.025260130915860855, 0.19118792845166516], [0.047554007832373228, 0.089386708435387069], [0.056465133708423168, 0.12590041576023511], [0.08490501733055128, 0.17656065024834713], [0.46115165848829304, 0.62487955749938184], [0.84326205652690578, 1.4004245004909552], [0.88087248433221854, 1.3785202239499517], [0.89268295394102337, 1.3741104645058173]]
evals2 = [[0.21693109285489523, 0.64867853349604365], [0.14847633965446119, 0.44543296204891647], [0.33522860257983056, 1.0056858072835722], [0.21440866064003394, 0.64322598075109028], [0.034748268106175186, 0.10200969947813054], [0.018203591010824915, 0.26736524573022236], [0.2174437740016725, 0.65687963768636082], [0.31401686717297883, 0.94185860742239047], [0.23085587996726545, 0.69194201410277434], [0.19816342632274134, 0.59323139247507473]]
evecs2 = [[12.955179820819147, 2.5750787505147308], [51.487733592121188, 1.6533220387658296], [9532.9898876010848, 20.462898710819797], [1.3607948475978142, 0.99998658466212575], [17.742048499811379, 3.5622654983228506], [10.876297539067858, 6.4404558356346131], [8.3613542372363856, 0.71488876503951249], [585.31700300005355, 28.67877502817591], [1352.5774967420894, 85.511115073810444], [2398.6185606572758, 177.70600634980369]]


if 1:
  plt.figure()
  plt.semilogx(eps, [x[0] for x in evals1])
  plt.semilogx(eps, [x[1] for x in evals1])
  plt.title('$\sigma^2= 4$, 200,000 samples (breaking spherality, independence, and data distribution)')
  plt.xlabel('$\epsilon$')
  plt.ylabel('relative error in $w_i$ approximation')
  plt.legend(['$|\hat{w}_1 - w_1| / |w_1|$', '$|\hat{w}_2 - w_2| / |w_2|$'], loc=2)
  plt.show()
  
  plt.figure()
  plt.semilogx(eps, [x[0] for x in evecs1])
  plt.semilogx(eps, [x[1] for x in evecs1])
  plt.title('$\sigma^2= 4$, 200,000 samples (breaking spherality, independence, and data distribution)')
  plt.xlabel('$\epsilon$')
  plt.ylabel('relative error in $\mu_h$ approximation')
  plt.legend(['$||\hat{\mu}_1 - \mu_1||_2$', '$||\hat{\mu}_2 - \mu_2||_2$'], loc=2)
  plt.show()
